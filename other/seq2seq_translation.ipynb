{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train_efr = pd.read_json(f'../data/EDiReF_train_data/MaSaC_train_efr.json')\n",
    "df_val_efr = pd.read_json(f'../data/EDiReF_val_data/MaSaC_val_efr.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One translation option\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"utter-project/EuroLLM-1.7B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"utter-project/EuroLLM-1.7B\")\n",
    "\n",
    "text = \"Hindi: Aaj to bhot awful day tha!. English:\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=20)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kasia\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "# Second translation option\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from pyhinavrophonetic import hinavro\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_conversation(conv):\n",
    "    translated_text = []\n",
    "    for s in conv:\n",
    "        text = hinavro.parse(s)\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "        outputs = model.generate(**inputs, forced_bos_token_id = tokenizer.convert_tokens_to_ids(\"eng_Latn\"), max_length = 30)\n",
    "        translated_text.append(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_efr.loc[:1, 'utterances'] = df_train_efr.loc[:1, 'utterances'].apply(translate_conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_efr.to_json(f'../data/EDiReF_{stage}_data/MaSaC_translated_{stage}_efr.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_efr['utterances'] = df_val_efr['utterances'].apply(translate_conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_efr.to_json(f'data/EDiReF_val_data/MaSaC_translated_val_efr.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sure, here's a translation of \"theek se wajan karana\" in English:\n",
      "\n",
      "\"It's good to take things slowly.\"\n",
      "-------------------------\n",
      "\n",
      "Sure, I'd be happy to help you with that! Can you please provide the Hindi text you would like me to translate into English?\n",
      "-------------------------\n",
      "\n",
      "Sure! Here's the translation of \"Abhi ayi\" and \"Yeh, ye bhi rakho\" in English:\n",
      "\n",
      "\"Abhi ayi\" can be translated to \"She has come.\"\n",
      "\n",
      "\"Yeh, ye bhi rakho\" can be translated to \"Keep these too.\"\n",
      "-------------------------\n",
      "\n",
      "Sorry to hear that you are experiencing issues with the translator. Can you please provide more context or information about the error you are receiving? Additionally, can you please specify which language you are trying to translate from and to? This will help me assist you better.\n",
      "-------------------------\n",
      "The phrase \"to kisee aur churidaar ka nara nikalke dalo na isme sahil\" in Hindi can be translated to \"Don't spread rumors about someone or cause trouble for them, it's not right.\"\n",
      "\n",
      "Here's a breakdown of the phrase:\n",
      "\n",
      "* \"To\" means \"don't\" or \"not\".\n",
      "* \"kisee\" means \"someone\" or \"anyone\".\n",
      "* \"aur\" means \"or\".\n",
      "* \"churidaar\" means \"trouble\" or \"problem\".\n",
      "* \"ka\" is a possessive pronoun meaning \"belonging to\".\n",
      "* \"nara\" means \"rumor\" or \"gossip\".\n",
      "* \"nikalke\" means \"spread\".\n",
      "* \"dalo\" means \"do not\".\n",
      "* \"na\" means \"not\".\n",
      "* \"isme\" means \"in this\".\n",
      "* \"sahil\" means \"right\" or \"proper\".\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "#Third translation option\n",
    "import ollama\n",
    "\n",
    "conversation = df_train_efr['utterances'][0]\n",
    "\n",
    "for sentence in conversation:\n",
    "    response = ollama.chat(model='llama2', messages=[\n",
    "      {\n",
    "        'role': 'user',\n",
    "        'content': f'Hindi: {sentence}. English: <translated_text>',\n",
    "      },\n",
    "    ])\n",
    "\n",
    "    print(response['message']['content'])\n",
    "    print('-'*25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
