{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s8mhsKQ4Ao2n",
    "outputId": "32dbc532-24d9-4891-ade2-310f49a54106"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3jmV21I1Asjp",
    "outputId": "7400d2ab-cc14-40a2-b7fa-e211150d48c7"
   },
   "outputs": [],
   "source": [
    "cd drive/MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S3sELgVlAuKx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uTE_5i6TAwPJ",
    "outputId": "d702f8b3-ad0b-4147-a196-2ddb0f946e74"
   },
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQu7dPCGAyfw"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_json('data/EDiReF_train_data/MELD_train_efr.json')\n",
    "train_df[\"triggers\"] = train_df[\"triggers\"].apply(lambda lst: [np.nan if x is None else x for x in lst])\n",
    "train_df = train_df[train_df[\"triggers\"].apply(lambda lst: not any(pd.isna(x) for x in lst))]\n",
    "\n",
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]\n",
    "\n",
    "flattened_emotions = flatten(train_df['emotions'])\n",
    "unique_emotions = set(flattened_emotions)\n",
    "\n",
    "labels_to_ids = {k: v for v, k in enumerate(unique_emotions)}\n",
    "ids_to_labels = {v: k for v, k in enumerate(unique_emotions)}\n",
    "\n",
    "train_conversations = list(train_df['utterances'])\n",
    "train_emotions = [[labels_to_ids[emotion] for emotion in conv] for conv in list(train_df['emotions'])]\n",
    "train_triggers = list(train_df['triggers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-TSgvkNAz_B"
   },
   "outputs": [],
   "source": [
    "val_df = pd.read_json('data/EDiReF_val_data/MELD_val_efr.json')\n",
    "val_df[\"triggers\"] = val_df[\"triggers\"].apply(lambda lst: [np.nan if x is None else x for x in lst])\n",
    "val_df = val_df[val_df[\"triggers\"].apply(lambda lst: not any(pd.isna(x) for x in lst))]\n",
    "\n",
    "val_conversations = list(val_df['utterances'])\n",
    "val_emotions = [[labels_to_ids[emotion] for emotion in conv] for conv in list(val_df['emotions'])]\n",
    "val_triggers = list(val_df['triggers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lUgr4gM4A15q"
   },
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R26m430iA3nR"
   },
   "outputs": [],
   "source": [
    "def tokenize_conversation(conversations, max_length = 128):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for conversation in conversations:\n",
    "        dialogue = \" [SEP] \".join(conversation)\n",
    "        encoded = tokenizer(\n",
    "            dialogue,\n",
    "            truncation = True,\n",
    "            padding = 'max_length',\n",
    "            max_length = max_length,\n",
    "            return_tensors = \"pt\"\n",
    "        )\n",
    "        input_ids.append(encoded[\"input_ids\"].squeeze(0))\n",
    "        attention_masks.append(encoded[\"attention_mask\"].squeeze(0))\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sj-cvC1iA4yq"
   },
   "outputs": [],
   "source": [
    "def pad_labels(labels, max_length = 128):\n",
    "    padded_labels = []\n",
    "    for label_set in labels:\n",
    "        label_tensor = torch.tensor(label_set, dtype = torch.float)\n",
    "        # Pad with -1 to ignore padding tokens in the loss function\n",
    "        padded_tensor = torch.cat(\n",
    "            [label_tensor, torch.full((max_length - len(label_set),), -1)]\n",
    "        )\n",
    "        padded_labels.append(padded_tensor)\n",
    "    return padded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Spv3M6DAA6QZ"
   },
   "outputs": [],
   "source": [
    "class ConversationDataset(Dataset):\n",
    "    def __init__(self, input_ids, attention_masks, emotion_labels, trigger_labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_masks = attention_masks\n",
    "        self.emotion_labels = emotion_labels\n",
    "        self.trigger_labels = trigger_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_masks[idx],\n",
    "            \"emotion_labels\": self.emotion_labels[idx],\n",
    "            \"trigger_labels\": self.trigger_labels[idx],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RYeFCsv0cYYv"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 256    # @param [96, 128, 256] {type: 'raw'}\n",
    "BATCH_SIZE = 8    # @param [16, 32, 64] {type: 'raw'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B8C81-H5A7pC"
   },
   "outputs": [],
   "source": [
    "train_input_ids, train_attention_masks = tokenize_conversation(train_conversations, max_length = MAX_LENGTH)\n",
    "\n",
    "train_emotion_labels = pad_labels(train_emotions, max_length = MAX_LENGTH)\n",
    "train_trigger_labels = pad_labels(train_triggers, max_length = MAX_LENGTH)\n",
    "\n",
    "train_dataset = ConversationDataset(train_input_ids, train_attention_masks, train_emotion_labels, train_trigger_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ra73vSjtA9hS"
   },
   "outputs": [],
   "source": [
    "val_input_ids, val_attention_masks = tokenize_conversation(val_conversations, max_length = MAX_LENGTH)\n",
    "\n",
    "val_emotion_labels = pad_labels(val_emotions, max_length = MAX_LENGTH)\n",
    "val_trigger_labels = pad_labels(val_triggers, max_length = MAX_LENGTH)\n",
    "\n",
    "val_dataset = ConversationDataset(val_input_ids, val_attention_masks, val_emotion_labels, val_trigger_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RK2rMABgA-y4"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = False)\n",
    "val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sbR-GOKJDMLS"
   },
   "outputs": [],
   "source": [
    "NUM_EXPERTS = 8 # @param [2, 4, 8] {type: 'raw'}\n",
    "TOP_K = 4 # @param [1, 2, 4, 8] {type: 'raw'}\n",
    "LEARNING_RATE = 0.00001 # @param [\"0.00001\", \"0.00002\",\"0.00005\",\"0.0001\"] {\"type\":\"raw\"}\n",
    "NUM_EPOCHS = 25 # @param [\"5\", \"10\", \"15\", \"20\", \"25\"] {\"type\":\"raw\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JXwJN1loitSu"
   },
   "outputs": [],
   "source": [
    "assert TOP_K <= NUM_EXPERTS, \"Select different values for TOP_K and NUM_EXPERTS!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4t1D1EAvBAXk"
   },
   "outputs": [],
   "source": [
    "class MoEForEmotionAndTriggerClassification(nn.Module):\n",
    "    def __init__(self, num_experts, num_classes, k, model_name = 'roberta-base'):\n",
    "        super(MoEForEmotionAndTriggerClassification, self).__init__()\n",
    "\n",
    "        self.roberta = RobertaModel.from_pretrained(model_name)\n",
    "        for param in self.roberta.parameters():\n",
    "            param.requires_grad = True  # Set to True if you want to fine-tune RoBERTa\n",
    "        hidden_size = self.roberta.config.hidden_size\n",
    "\n",
    "        self.gating_network = nn.Linear(hidden_size, num_experts)\n",
    "        self.experts = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(num_experts)])\n",
    "\n",
    "        self.emotion_classifier = nn.Linear(hidden_size, num_classes)\n",
    "        self.trigger_classifier = nn.Linear(hidden_size, 1)\n",
    "\n",
    "        self.k = k\n",
    "        self.dropout = nn.Dropout(p = 0.1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        roberta_outputs = self.roberta(input_ids = input_ids, attention_mask = attention_mask)\n",
    "        embeddings = roberta_outputs.last_hidden_state  # (batch_size, seq_len, hidden_size)\n",
    "        pooled_embeddings = embeddings.mean(dim = 1)    # (batch_size, hidden_size)\n",
    "        pooled_embeddings = self.dropout(pooled_embeddings)\n",
    "\n",
    "        expert_weights = self.gating_network(pooled_embeddings) # (batch_size, num_experts)\n",
    "        expert_weights = torch.softmax(expert_weights, dim = -1)\n",
    "\n",
    "        # top-k experts only are activated\n",
    "        topk_weights, topk_indices = torch.topk(expert_weights, self.k, dim = -1)\n",
    "\n",
    "        combined_output = torch.zeros_like(embeddings)  # (batch_size, seq_len, hidden_size)\n",
    "\n",
    "        for i in range(self.k):\n",
    "            expert_idx = topk_indices[:, i]\n",
    "            weight = topk_weights[:, i].unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "            expert_outputs = torch.stack(\n",
    "                [self.experts[expert_idx[j]](embeddings[j]) for j in range(expert_idx.size(0))]\n",
    "            )\n",
    "            combined_output += weight * expert_outputs  # (batch_size, hidden_size)\n",
    "\n",
    "        combined_output = self.dropout(combined_output)\n",
    "        emotion_logits = self.emotion_classifier(combined_output)   # (batch_size, seq_len, num_classes)\n",
    "        trigger_logits = self.trigger_classifier(combined_output).squeeze(-1)   # (batch_size, seq_len)\n",
    "\n",
    "        return emotion_logits, trigger_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F3vNaiUdBEtR",
    "outputId": "9f861a02-cee2-4daa-a914-27cd653714dc"
   },
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss, BCEWithLogitsLoss\n",
    "\n",
    "moe = MoEForEmotionAndTriggerClassification(num_experts = NUM_EXPERTS, num_classes = len(labels_to_ids), k = TOP_K)\n",
    "optimizer = AdamW(moe.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "emotion_loss_fn = CrossEntropyLoss()\n",
    "trigger_loss_fn = BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hEtK7lTnBGRY",
    "outputId": "6280edc6-7d52-4ebe-ca19-36c7580a849d"
   },
   "outputs": [],
   "source": [
    "moe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLm5ynUwBHxx"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    val_loss, nb_steps = 0.0, 0\n",
    "    total_emotion_preds, correct_emotion_preds = 0, 0\n",
    "    total_trigger_preds, correct_trigger_preds = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(val_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            emotion_labels = batch['emotion_labels'].to(device)\n",
    "            trigger_labels = batch['trigger_labels'].to(device)\n",
    "\n",
    "            emotion_logits, trigger_logits = model(input_ids, attention_mask)\n",
    "\n",
    "            # removing padding\n",
    "            emotion_mask = emotion_labels != -1\n",
    "\n",
    "            emotion_logits_flat = emotion_logits.view(-1, emotion_logits.size(-1))\n",
    "            emotion_labels_flat = emotion_labels.view(-1)\n",
    "\n",
    "            emotion_logits = emotion_logits_flat[emotion_mask.view(-1)]\n",
    "            emotion_labels = emotion_labels_flat[emotion_mask.view(-1)]\n",
    "\n",
    "            trigger_mask = trigger_labels != -1\n",
    "\n",
    "            trigger_logits_flat = trigger_logits.view(-1)\n",
    "            trigger_labels_flat = trigger_labels.view(-1)\n",
    "\n",
    "            trigger_logits = trigger_logits_flat[trigger_mask.view(-1)]\n",
    "            trigger_labels = trigger_labels_flat[trigger_mask.view(-1)]\n",
    "\n",
    "            # calculating loss\n",
    "            emotion_loss = emotion_loss_fn(emotion_logits, emotion_labels.long())\n",
    "            trigger_loss = trigger_loss_fn(trigger_logits, trigger_labels)\n",
    "\n",
    "            loss = emotion_loss + trigger_loss\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # calculating accuracy\n",
    "            emotion_preds = torch.argmax(emotion_logits, dim=-1)\n",
    "            trigger_preds = (torch.sigmoid(trigger_logits).squeeze(-1) > 0.5).long()\n",
    "\n",
    "            correct_emotion_preds += torch.sum(emotion_preds == emotion_labels).item()\n",
    "            correct_trigger_preds += torch.sum(trigger_preds == trigger_labels).item()\n",
    "\n",
    "            total_emotion_preds += emotion_labels.numel()\n",
    "            total_trigger_preds += trigger_labels.numel()\n",
    "\n",
    "            nb_steps += 1\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                loss_step = val_loss / nb_steps\n",
    "                print(f'      Validation loss per 100 training steps: {loss_step}')\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        emotion_accuracy = correct_emotion_preds / total_emotion_preds\n",
    "        trigger_accuracy = correct_trigger_preds / total_trigger_preds\n",
    "        avg_val_accuracy = (emotion_accuracy + trigger_accuracy)/2\n",
    "\n",
    "    return avg_val_loss, avg_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TZ4gCPg3BJVR"
   },
   "outputs": [],
   "source": [
    "def train_and_validate(model, train_loader, val_loader, num_epochs = 3):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
    "        model.train()\n",
    "        train_loss, nb_steps = 0.0, 0\n",
    "        total_emotion_preds, correct_emotion_preds = 0, 0\n",
    "        total_trigger_preds, correct_trigger_preds = 0, 0\n",
    "\n",
    "        for idx, batch in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            emotion_labels = batch['emotion_labels'].to(device)\n",
    "            trigger_labels = batch['trigger_labels'].to(device)\n",
    "\n",
    "            emotion_logits, trigger_logits = model(input_ids, attention_mask)\n",
    "\n",
    "            # removing padding\n",
    "            emotion_mask = emotion_labels != -1\n",
    "\n",
    "            emotion_logits_flat = emotion_logits.view(-1, emotion_logits.size(-1))\n",
    "            emotion_labels_flat = emotion_labels.view(-1)\n",
    "\n",
    "            emotion_logits = emotion_logits_flat[emotion_mask.view(-1)]\n",
    "            emotion_labels = emotion_labels_flat[emotion_mask.view(-1)]\n",
    "\n",
    "            trigger_mask = trigger_labels != -1\n",
    "\n",
    "            trigger_logits_flat = trigger_logits.view(-1)\n",
    "            trigger_labels_flat = trigger_labels.view(-1)\n",
    "\n",
    "            trigger_logits = trigger_logits_flat[trigger_mask.view(-1)]\n",
    "            trigger_labels = trigger_labels_flat[trigger_mask.view(-1)]\n",
    "\n",
    "            # calculating loss\n",
    "            emotion_loss = emotion_loss_fn(emotion_logits, emotion_labels.long())\n",
    "            trigger_loss = trigger_loss_fn(trigger_logits, trigger_labels)\n",
    "\n",
    "            loss = emotion_loss + trigger_loss\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # calculating accuracy\n",
    "            emotion_preds = torch.argmax(emotion_logits, dim=-1)\n",
    "            trigger_preds = (torch.sigmoid(trigger_logits).squeeze(-1) > 0.5).long()\n",
    "\n",
    "            correct_emotion_preds += torch.sum(emotion_preds == emotion_labels).item()\n",
    "            correct_trigger_preds += torch.sum(trigger_preds == trigger_labels).item()\n",
    "\n",
    "            total_emotion_preds += emotion_labels.numel()\n",
    "            total_trigger_preds += trigger_labels.numel()\n",
    "            nb_steps += 1\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                loss_step = train_loss / nb_steps\n",
    "                print(f'      Training loss per 100 training steps: {loss_step}')\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        emotion_accuracy = correct_emotion_preds / total_emotion_preds\n",
    "        trigger_accuracy = correct_trigger_preds / total_trigger_preds\n",
    "        avg_train_accuracy = (emotion_accuracy + trigger_accuracy)/2\n",
    "\n",
    "        val_loss, val_accuracy = evaluate(model, val_loader)\n",
    "\n",
    "        print(f\"   Training Loss: {avg_train_loss:.3f}, Training Accuracy: {avg_train_accuracy:.3f}\")\n",
    "        print(f\"   Validation Loss: {val_loss:.3f}, Validation Accuracy: {val_accuracy:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9icUMwFaBL8Z",
    "outputId": "99a58f1e-ab58-4c79-f983-e5e226f83806"
   },
   "outputs": [],
   "source": [
    "train_and_validate(moe, train_loader, val_loader, num_epochs = NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zkmg0NFqBOTp"
   },
   "outputs": [],
   "source": [
    "torch.save(moe.state_dict(), f'trained_models/moe_model_{NUM_EXPERTS}_experts_{TOP_K}_active_{LEARNING_RATE}_lr_{NUM_EPOCHS}_epochs.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TCjA8jYsEy56"
   },
   "outputs": [],
   "source": [
    "moe_loaded = MoEForEmotionAndTriggerClassification(num_experts = NUM_EXPERTS, num_classes = len(labels_to_ids), k = TOP_K)\n",
    "moe_loaded.load_state_dict(torch.load(f'trained_models/moe_model_{NUM_EXPERTS}_experts_{TOP_K}_active_{LEARNING_RATE}_lr_{NUM_EPOCHS}_epochs.pth', map_location=torch.device(\"cpu\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2MYDm5EEBTVj"
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_json('/content/drive/MyDrive/MELD_test_efr.json')\n",
    "\n",
    "test_conversations = list(test_df['utterances'])\n",
    "test_emotions = [[labels_to_ids[emotion] for emotion in conv] for conv in list(test_df['emotions'])]\n",
    "test_triggers = [[-1.0 for sent in conv] for conv in test_emotions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hf-zp1c-BT1w"
   },
   "outputs": [],
   "source": [
    "test_input_ids, test_attention_masks = tokenize_conversation(test_conversations, max_length = MAX_LENGTH)\n",
    "\n",
    "test_emotion_labels = pad_labels(test_emotions, max_length = MAX_LENGTH)\n",
    "test_trigger_labels = pad_labels(test_triggers, max_length = MAX_LENGTH)\n",
    "\n",
    "test_dataset = ConversationDataset(test_input_ids, test_attention_masks, test_emotion_labels, test_trigger_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHall7cMBVja"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "moe_loaded.to(device)\n",
    "moe_loaded.eval()\n",
    "\n",
    "total_emotion_preds, correct_emotion_preds = 0, 0\n",
    "test_accuracy = 0.0\n",
    "test_precision = 0.0\n",
    "test_recall = 0.0\n",
    "test_f1 = 0.0\n",
    "num_samples, nb_steps = 0, 0\n",
    "\n",
    "for batch in test_loader:\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    emotion_labels = batch['emotion_labels'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        emotion_logits, _ = moe_loaded(input_ids, attention_mask)\n",
    "\n",
    "        # Compute predictions\n",
    "        emotion_mask = emotion_labels != -1\n",
    "\n",
    "        emotion_logits_flat = emotion_logits.view(-1, emotion_logits.size(-1))\n",
    "        emotion_labels_flat = emotion_labels.view(-1)\n",
    "\n",
    "        emotion_logits = emotion_logits_flat[emotion_mask.view(-1)]\n",
    "        emotion_labels = emotion_labels_flat[emotion_mask.view(-1)]\n",
    "\n",
    "        emotion_preds = torch.argmax(emotion_logits, dim = -1)\n",
    "\n",
    "        # Calculate metrics for emotion classification\n",
    "        emotion_preds_flat = emotion_preds.cpu().numpy()\n",
    "        emotion_labels_flat = emotion_labels.cpu().numpy()\n",
    "\n",
    "        test_accuracy += torch.sum(emotion_preds == emotion_labels).item()\n",
    "\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            emotion_labels_flat, emotion_preds_flat, average='weighted', zero_division = 0\n",
    "        )\n",
    "\n",
    "        test_precision += precision\n",
    "        test_recall += recall\n",
    "        test_f1 += f1\n",
    "        num_samples += len(emotion_labels_flat)\n",
    "        nb_steps += 1\n",
    "\n",
    "# Calculate average metrics\n",
    "avg_accuracy = test_accuracy / num_samples\n",
    "avg_precision = test_precision / nb_steps\n",
    "avg_recall = test_recall / nb_steps\n",
    "avg_f1 = test_f1 / nb_steps\n",
    "\n",
    "# Output results\n",
    "print(\"Emotion classification:\")\n",
    "print(f\"   Test Accuracy: {avg_accuracy:.3f}\")\n",
    "print(f\"   Test Precision: {avg_precision:.3f}\")\n",
    "print(f\"   Test Recall: {avg_recall:.3f}\")\n",
    "print(f\"   Test F1-score: {avg_f1:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
